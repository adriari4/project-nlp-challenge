{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Introduction\n",
    "Learning how to process text is a skill required for Data Scientists/AI Engineers.\n",
    "In this project, you will put these skills into practice to identify whether a news headline is real or fake news.\n",
    "\n",
    "Project Overview\n",
    "In the file dataset/data.csv, you will find a dataset containing news articles with the following columns:\n",
    "\n",
    "- label: 0 if the news is fake, 1 if the news is real.\n",
    "- title: The headline of the news article.\n",
    "- text: The full content of the article.\n",
    "- subject: The category or topic of the news.\n",
    "- date: The publication date of the article.\n",
    "- Your goal is to build a classifier that is able to distinguish between the two.\n",
    "\n",
    "Once you have a classifier built, then use it to predict the labels for dataset/validation_data.csv. Generate a new file where the label 2 has been replaced by 0 (fake) or 1 (real) according to your model. Please respect the original file format, do not include extra columns, and respect the column separator.\n",
    "\n",
    "Please ensure to split the data.csv into training and test datasets before using it for model training or evaluation.\n",
    "\n",
    "Guidance\n",
    "Like in a real life scenario, you are able to make your own choices and text treatment. Use the techniques you have learned and the common packages to process this data and classify the text.\n",
    "\n",
    "Deliverables\n",
    "- Python Code: Provide well-documented Python code that conducts the analysis.\n",
    "- Predictions: A csv file in the same format as validation_data.csv but with the predicted labels (0 or 1)\n",
    "- Accuracy estimation: Provide the teacher with your estimation of how your model will perform.\n",
    "- Presentation: You will present your model in a 10-minute presentation. Your teacher will provide further instructions.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load & quick sanity checks\n",
    "# Goal: confirm columns, size, nulls, class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Train/test split (from data.csv)\n",
    "# Use stratified split on label to preserve class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Choose features (text) & minimal preprocessing.\n",
    "# Easiest strong baseline: TF-IDF on title + text. Optionally include subject as a categorical feature later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Vectorizer + model in a Pipeline\n",
    "# Start with TfidfVectorizer + LogisticRegression (fast, strong baseline).\n",
    "# You can swap in LinearSVC or MultinomialNB later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Fit & evaluate (baseline)\n",
    "# Use accuracy and precision/recall/F1 (binary classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) (Optional) Quick hyperparameter search\n",
    "# Small grid to avoid overfitting your time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Train on full training data (optional)\n",
    "# After choosing final settings (pipe or best_model), you can refit on all of df for maximal signal before producing validation predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Produce predictions for validation_data.csv\n",
    "# The file format must be the same as the original, but with label 2 replaced by your predictions (0/1).\n",
    "# Usually validation_data.csv has label=2 as a placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Accuracy estimation (what to report)\n",
    "# Report test set metrics from step 5 (or your CV estimates).\n",
    "# State: test accuracy, precision/recall/F1 for each class, and any notable error patterns (e.g., satire mistaken as fake)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) (Optional) Nice upgrades\n",
    "# Use subject: combine with text via ColumnTransformer.\n",
    "# Use date: extract year/month; sometimes correlates with patterns.\n",
    "# Calibrate probabilities (CalibratedClassifierCV) if you want threshold tuning.\n",
    "# Error analysis: inspect top false positives/negatives to refine preprocessing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
